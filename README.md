# ğŸš€ **End-to-End MLOps Project**

A **production-grade machine learning pipeline** that spans the complete lifecycle â€” from **data ingestion** and **model training** to **deployment on AWS EKS** with full **CI/CD automation** and **real-time monitoring**.

---

## ğŸŒŸ **Key Features**

### âœ… MLOps Best Practices

* ğŸ” **Reproducible pipelines** using `DVC`
* ğŸ§ª **Experiment tracking** with `MLflow` hosted on Dagshub
* ğŸ¤– **Automated CI/CD** via `GitHub Actions`

### ğŸ³ Containerization & Scalable Deployment

* ğŸ“¦ Packaged with `Docker`
* ğŸš€ Deployed on **AWS EKS (Kubernetes)**
* ğŸŒ REST API built using `Flask`

### ğŸ“ˆ Monitoring & Observability

* ğŸ“Š Metrics with `Prometheus`
* ğŸ“‰ Dashboards with `Grafana`

### â˜ï¸ Cloud Infrastructure

* ğŸ—‚ï¸ `AWS S3` for artifact storage
* ğŸ“¤ `AWS ECR` for Docker images
* ğŸ” `AWS IAM` for secure access management

---

## âš™ï¸ **Technology Stack**

| Area                   | Tools & Services              |
| ---------------------- | ----------------------------- |
| ğŸ“ Project Structure   | `cookiecutter-data-science`   |
| ğŸ§ª Experiment Tracking | `MLflow`, `Dagshub`           |
| ğŸ“¦ Data Versioning     | `DVC`, `AWS S3`               |
| ğŸ§ª Environment         | `Conda`, `Pip`, `Docker`      |
| ğŸš€ Deployment          | `Flask`, `Docker`, `AWS EKS`  |
| ğŸ”„ CI/CD               | `GitHub Actions`              |
| ğŸ“ˆ Monitoring          | `Prometheus`, `Grafana`       |
| â˜ Cloud Services       | `AWS IAM`, `S3`, `ECR`, `EKS` |

---

## ğŸ”„ **MLOps Lifecycle Workflow**

```mermaid
flowchart TD
    START["ğŸš€ MLOps Lifecycle Start"]
    INGEST["ğŸ“¥ Data Ingestion"]
    PREPROCESS["ğŸ§¹ Data Preprocessing & Feature Engineering"]
    TRAIN["ğŸ¤– Model Training & MLflow Tracking"]
    VERSION["ğŸ“¦ DVC + AWS S3"]
    CONTAINER["ğŸ³ Docker Containerization"]
    DEPLOY["ğŸ§¬ Deployment on AWS EKS"]
    MONITOR["ğŸ“ˆ Monitoring with Prometheus & Grafana"]

    START --> INGEST --> PREPROCESS --> TRAIN --> VERSION
    TRAIN --> CONTAINER --> DEPLOY --> MONITOR
```
## ğŸ“ **Setup & Flow**

### ğŸ”¹ Repository & Structure

âœ… Initialize project: `cookiecutter-data-science`
âœ… Organize src into: `data_ingestion.py`, `data_preprocessing.py`, `feature_engineering.py`, `model_building.py`, `model_evaluation.py`, `register_model.py`

---

### ğŸ”¹ Experiment Tracking

âœ… MLflow + Dagshub integrated
âœ… All experiments logged and reproducible

---

### ğŸ”¹ Data & Model Management

âœ… DVC initialized with **local & S3 remotes**
âœ… `params.yaml`, `dvc.yaml` for pipeline management
âœ… `dvc repro` for full pipeline execution

---

### ğŸ”¹ CI/CD Pipeline

âœ… GitHub Actions for:

* Code linting & testing
* Docker build & push to ECR
* Kubernetes deployment on EKS

âœ… Secrets managed via GitHub & Dagshub tokens

---

### ğŸ”¹ Deployment & Scaling

âœ… Flask app containerized with **Docker**
âœ… EKS cluster setup with **eksctl**
âœ… LoadBalancer service exposing API

---

### ğŸ”¹ Monitoring

âœ… Prometheus scrapes app metrics
âœ… Grafana visualizes & alerts on metrics

---

## ğŸŒ **Cloud Resources**

* **AWS EKS Cluster:** Auto-managed nodes
* **AWS S3:** Model artifacts & datasets
* **AWS ECR:** Container image repository
* **AWS IAM:** Fine-grained access control

---

## ğŸ–¥ **Access**

ğŸ”— **Grafana Dashboard:** `http://<grafana-ip>:3000`
ğŸ”— **Prometheus Web UI:** `http://<prometheus-ip>:9090`
ğŸ”— **Flask API:** `http://<load-balancer-ip>:5000`

---

## ğŸ§¹ **Cleanup**

âœ… Tear down EKS, S3, ECR, EC2, and other AWS resources post-deployment
âœ… CloudFormation stacks cleaned

---

## ğŸ¤© **Why this project?**

This project demonstrates **full-cycle MLOps engineering**:
âœ… **Reproducibility** (DVC, MLflow)
âœ… **Automation** (CI/CD, GitHub Actions)
âœ… **Scalability** (Kubernetes on AWS EKS)
âœ… **Monitoring** (Prometheus + Grafana)
âœ… **Cloud readiness** (S3, ECR, IAM)

---

## ğŸ“Œ **How to Run**

```bash
# Clone and setup
git clone https://github.com/your-username/your-repo.git
cd your-repo
conda create -n atlas python=3.10
conda activate atlas
pip install -r requirements.txt

# Reproduce pipeline
dvc repro

# Build Docker
docker build -t capstone-app:latest .
docker run -p 8888:5000 -e CAPSTONE_TEST=your-token capstone-app:latest

# Deploy to EKS (via CI or manually)
kubectl apply -f k8s/deployment.yaml
```

---

## ğŸŒŸ **Screenshots**

<details>
<summary>App UI</summary>
<img src="./project_images/App UI.png" alt="MLflow tracking" width="600"/>
</details>

<details>
<summary>MLflow UI</summary>
<img src="./project_images/MLFlow.png" alt="MLflow tracking" width="600"/>
</details>


<details>
<summary>App Metrics</summary>
<img src="./project_images/Metrics.png" alt="Grafana monitoring" width="600"/>
</details>

<details>
<summary>Prometheus Metrics</summary>
<img src="./project_images/Promtheus.png" alt="Prometheus" width="600"/>
</details>

<details>
<summary>Grafana Dashboard</summary>
<img src="./project_images/Grafana.png" alt="MLflow tracking" width="600"/>
</details>

---

## ğŸ’¡ **Future Enhancements**

* Auto-trigger retraining on data drift
* Canary deployments on Kubernetes
* Advanced metrics: latency, memory, GPU utilization

---

## ğŸ“« **Letâ€™s Connect**

ğŸ’¼ [LinkedIn](https://www.linkedin.com/in/shrishti-singh-t/)
